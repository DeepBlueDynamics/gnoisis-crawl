#!/usr/bin/env python3
"""
Test script for gnosis-crawl batch job system
Usage: 
  python test_batch_crawl.py --service-token <service_token>
"""
import asyncio
import httpx
import json
import time
import argparse
import sys

def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description="Test gnosis-crawl batch job system")
    parser.add_argument("--service-token", help="Service token for direct crawl service auth", required=True)
    parser.add_argument("--crawl-url", default="http://localhost:6792", help="Crawl service URL")
    parser.add_argument("--timeout", type=int, default=30, help="Max wait time for job completion")
    return parser.parse_args()

async def get_jwt_token(ahp_url: str, api_token: str):
    """Get JWT token from AHP using API token"""
    print("üîë Getting JWT token from AHP...")
    
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                f"{ahp_url}/auth",
                json={"token": api_token}
            )
            
            if response.status_code == 200:
                data = response.json()
                jwt_token = data.get("token")
                print(f"‚úÖ Got JWT token: {jwt_token[:20]}...")
                return jwt_token
            else:
                print(f"‚ùå Failed to get JWT token: {response.status_code} - {response.text}")
                return None
    except Exception as e:
        print(f"‚ùå Error getting JWT token: {e}")
        return None

async def test_batch_crawl(jwt_token, crawl_url):
    """Test batch crawl job submission"""
    print("\nüöÄ Testing batch crawl job...")
    
    # Test URLs
    test_urls = [
        "https://httpbin.org/json",
        "https://httpbin.org/user-agent", 
        "https://example.com"
    ]
    
    batch_request = {
        "urls": test_urls,
        "javascript": False,  # Faster without JS
        "screenshot": False,
        "max_concurrent": 2,
        "callback_url": "https://webhook.site/test-batch-crawl"
    }
    
    headers = {
        "Authorization": f"Bearer {jwt_token}",
        "Content-Type": "application/json"
    }
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(
                f"{crawl_url}/api/jobs/batch-crawl",
                json=batch_request,
                headers=headers
            )
            
            if response.status_code == 200:
                data = response.json()
                print(f"‚úÖ Batch job created successfully!")
                print(f"   Job ID: {data['job_id']}")
                print(f"   Session ID: {data['session_id']}")
                print(f"   Message: {data['message']}")
                return data['session_id']
            else:
                print(f"‚ùå Failed to create batch job: {response.status_code}")
                print(f"   Response: {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error submitting batch job: {e}")
            return None

async def check_session_status(jwt_token, session_id, crawl_url):
    """Check session status"""
    print(f"\nüìä Checking session status for: {session_id}")
    
    headers = {
        "Authorization": f"Bearer {jwt_token}",
        "Content-Type": "application/json"
    }
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.get(
                f"{crawl_url}/api/sessions/{session_id}/status",
                headers=headers
            )
            
            if response.status_code == 200:
                data = response.json()
                print("‚úÖ Session status:")
                print(json.dumps(data, indent=2))
                return data
            else:
                print(f"‚ùå Failed to get status: {response.status_code}")
                print(f"   Response: {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error getting status: {e}")
            return None

async def wait_for_completion(jwt_token, session_id, crawl_url, max_wait=60):
    """Wait for job completion"""
    print(f"\n‚è≥ Waiting for job completion (max {max_wait}s)...")
    
    start_time = time.time()
    while time.time() - start_time < max_wait:
        status = await check_session_status(jwt_token, session_id, crawl_url)
        
        if status:
            stage = status.get("stages", {}).get("crawling", {})
            if stage.get("status") == "complete":
                print("‚úÖ Job completed!")
                return True
            elif stage.get("status") == "failed":
                print("‚ùå Job failed!")
                return False
            else:
                progress = stage.get("progress_percent", 0)
                processed = stage.get("urls_processed", 0) 
                total = stage.get("total_urls", 0)
                print(f"   Progress: {progress}% ({processed}/{total} URLs)")
        
        await asyncio.sleep(5)
    
    print("‚è∞ Timeout waiting for completion")
    return False

async def get_session_results(jwt_token, session_id, crawl_url):
    """Get session results"""
    print(f"\nüì• Getting session results for: {session_id}")
    
    headers = {
        "Authorization": f"Bearer {jwt_token}",
        "Content-Type": "application/json"
    }
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.get(
                f"{crawl_url}/api/sessions/{session_id}/results",
                headers=headers
            )
            
            if response.status_code == 200:
                data = response.json()
                print("‚úÖ Session results:")
                
                # Show summary
                results = data.get("results", [])
                print(f"   Total results: {len(results)}")
                
                # Show each result summary
                for i, result in enumerate(results):
                    url = result.get("url", "Unknown")
                    success = result.get("result", {}).get("success", False)
                    markdown_len = len(result.get("result", {}).get("markdown", ""))
                    print(f"   {i+1}. {url}: {'‚úÖ' if success else '‚ùå'} ({markdown_len} chars)")
                
                return data
            else:
                print(f"‚ùå Failed to get results: {response.status_code}")
                print(f"   Response: {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error getting results: {e}")
            return None

async def main():
    """Main test function"""
    args = parse_args()
    
    print("üß™ Starting gnosis-crawl batch job test")
    print("=" * 50)
    
    # Step 1: Exchange service token for JWT
    service_token = args.service_token
    print(f"üîë Using service token: {service_token[:20]}...")
    
    # Get JWT token from AHP
    jwt_token = await get_jwt_token("http://localhost:5005", service_token)
    if not jwt_token:
        print("‚ùå Cannot proceed without JWT token")
        return False
    
    # Step 2: Submit batch crawl job
    session_id = await test_batch_crawl(jwt_token, args.crawl_url)
    if not session_id:
        print("‚ùå Cannot proceed without session ID")
        return False
    
    # Step 3: Monitor progress
    completed = await wait_for_completion(jwt_token, session_id, args.crawl_url, args.timeout)
    
    # Step 4: Get results (regardless of completion status)
    results = await get_session_results(jwt_token, session_id, args.crawl_url)
    
    print("\n" + "=" * 50)
    if completed and results:
        print("üéâ Batch crawl test completed successfully!")
        return True
    else:
        print("‚ö†Ô∏è Batch crawl test completed with issues")
        return False

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Test interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Test crashed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)